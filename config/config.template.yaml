# NOTE: this not an actual config used by the application. This is
# a template to show all configuration parameters.

server:
  port: 8001
  name: event-us-01 #This parameter is required in cluster deployments. If not set - will be taken from os.Hostname()
  #might be http url of file source
  #auth: https://source_of_tokens
  auth:
    js:
      - bd33c5fa-d69f-11ea-87d0-0242ac130003
      - c20765a0-d69f-15ea-82d0-0242ac130003
    api:
      - 5f15eba2-db58-11ea-87d0-0242ac130003
      - 62faa226-db58-11ea-87d0-0242ac130003
  auth_reload_sec: 60 #default value is 100.  If 'auth' is http or file:/// source than it will be reloaded every auth_reload_sec
  public_url: https://yourhost
  log:
    path: /home/eventnative/logs/ #omit this key to write log to stdout
    rotation_min: 60 #1440 (24 hours) default value
  destinations_reload_sec: 60 #default value is 120.  If 'destinations' is http or file:/// source than it will be reloaded every destinations_reload_sec

geo.maxmind_path: https://statichost/GeoIP2-City.mmdb

log:
  path: /home/eventnative/logs/events
  rotation_min: 5

#might be http url or file source
#destinations: https://source_of_destinations
destinations:
  redshift_one:
    type: redshift
    only_tokens: ['bd33c5fa-d69f-11ea-87d0-0242ac130003']
    mode: batch #Optional. Available mode: [batch, stream], default value: batch
    datasource:
      host: redshift.amazonaws.com
      db: my-db
      schema: myschema
      username: user
      password: pass
    s3:
      access_key_id: abc123
      secret_access_key: secretabc123
      bucket: my-bucket
      region: us-west-1
      folder: redshift_one #Optional. Specify this parameter if several destinations use one s3 bucket
    data_layout:
      mapping:
        - "/key1/key2 -> /key3"
        - "/key1/key3 -> (integer) /key4"
      table_name_template: '{{.event_type}}_{{._timestamp.Format "2006_01"}}' #template
  redshift_two:
    type: redshift
    only_tokens: ['c20765a0-d69f-15ea-82d0-0242ac130003']
    mode: stream
    datasource:
      host: redshift.amazonaws.com
      db: my-db-2
      username: user
      password: pass
    s3:
      access_key_id: abc456
      secret_access_key: secretabc456
      bucket: my-bucket-2
      region: us-west-1
    data_layout:
      table_name_template: 'views' #constant
  bigquery:
    only_tokens: ['bd33c5fa-d69f-11ea-87d0-0242ac130003', 'c20765a0-d69f-15ea-82d0-0242ac130003']
    google:
      gcs_bucket: google_cloud_storage_bucket
      bq_project: big_query_project
      bq_dataset: big_query_dataset # 'default' will be created if omitted
      key_file: /home/eventnative/app/res/bqkey.json # or json string of key e.g. "{"service_account":...}"
    data_layout:
      table_name_template: 'events' #constant
  postgres_ksense:
    type: postgres
    only_tokens: ['c20765a0-d69f-15ea-82d0-0242ac130003']
    mode: stream
    datasource:
      schema: ksense #'public' is default value
      host: your_host.com
      db: your_db
      username: your_username
      password: your_password
      parameters: #optional postgres connect db parameters (see https://www.postgresql.org/docs/9.1/libpq-connect.html)
        sslmode: disable
        connect_timeout: 300
    data_layout:
      table_name_template: 'events' #constant
  clickhouse_ksense:
    type: clickhouse
    only_tokens: ['bd33c5fa-d69f-11ea-87d0-0242ac130003', 'c20765a0-d69f-15ea-82d0-0242ac130003']
    clickhouse:
      dsns:
        - "https://username:password@host1:8443/mydb?read_timeout=5m&timeout=5m&enable_http_compression=1&tls_config=maincert"
        - "https://username:password@host2:8443/mydb?read_timeout=5m&timeout=5m&enable_http_compression=1&tls_config=maincert"
      db: mydb
      cluster: clustername #required. If dsns count > 1 or if Replicated* engines are used in raw_statement
      engine: #optional. If not provided - 'ReplacingMergeTree(_timestamp) ORDER BY (eventn_ctx_event_id) PARTITION BY toYYYYMM(_timestamp)' will be created or Replicated* one if cluster is provided
        raw_statement: 'ENGINE = ReplacingMergeTree(_timestamp) ORDER BY (eventn_ctx_event_id)' #optional. String will be used in 'CREATE TABLE ... $RAW_ENGINE' statement
        non_null_fields: #required if raw_statement is provided. You must specify all fields from partition clause, order clause, primary key clause
          - _timestamp
          - eventn_ctx_event_id
        #if raw_statement is provided - below parameters from 'engine' section will be skipped
        partition_fields:  #optional. If provided - it overrides PARTITION BY in CREATE TABLE statement
          - function: toYYYYMMDD #optional. It is used in 'PARTITION BY (toYYYYMMDD(_timestamp), event_type)'
            field: _timestamp
          - field: event_type
        order_fields: #optional. If provided - it overrides ORDER BY in CREATE TABLE statement with provided fields
          - function: intHash32 #optional. It is used in 'ORDER BY intHash32(id)'
            field: id
        primary_keys: #optional. If provided - it overrides PRIMARY KEY in CREATE TABLE statement with provided fields
          - eventn_ctx_event_id
      tls: #optional
        maincert: /home/eventnative/app/res/rootCa.crt
  s3_destination:
    type: s3
    only_tokens: ['bd33c5fa-d69f-11ea-87d0-0242ac130003']
    s3:
      access_key_id: abcd1234
      secret_access_key: secretabcd1234
      bucket: my-file-bucket
      region: us-east-1
      endpoint: #default: aws s3 endpoint. If you use DigitalOcean spaces or others - specify your endpoint
    data_layout:
      mapping:
        - "/key1/key2 -> /key3"
      table_name_template: '{{.event_type}}_{{._timestamp.Format "2006_01"}}' #template will be used for file naming